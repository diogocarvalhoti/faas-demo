# ğŸš€ Serverless na PrÃ¡tica: Desbravando o Mundo do FaaS

**Autor:** Diogo Carvalho de Matos â€“ Arquiteto de Software e SoluÃ§Ãµes  
**Tema:** Serverless na PrÃ¡tica: Desbravando o Mundo do FaaS  

---

## ğŸ§­ Agenda

### ğŸ“ **PARTE 1: VisÃ£o de Arquitetura/Infraestrutura**

1. **IntroduÃ§Ã£o ao FaaS** - Conceitos fundamentais
2. **Problemas que o FaaS resolve** - BenefÃ­cios e casos de uso
3. **Como os provedores implementam FaaS** - Arquiteturas e diferenÃ§as
4. **Knative: Serverless para Kubernetes** - Componentes e funcionamento
5. **ConfiguraÃ§Ã£o do Knative em cluster on-premise** - Setup passo a passo
6. **Arquitetura e escalabilidade** - Como funciona internamente

### ğŸ‘¨â€ğŸ’» **PARTE 2: VisÃ£o do Desenvolvedor** 

7. **Criando uma funÃ§Ã£o Spring Boot** - Desenvolvimento prÃ¡tico
8. **Build e Deploy** - Do cÃ³digo Ã  produÃ§Ã£o
9. **Testando a funÃ§Ã£o** - ValidaÃ§Ã£o e execuÃ§Ã£o
10. **Serverless em aÃ§Ã£o** - Escalabilidade automÃ¡tica e scale-to-zero
11. **ConclusÃµes e prÃ³ximos passos**

---

## ğŸ“ PARTE 1: VISÃƒO DE ARQUITETURA/INFRAESTRUTURA

> **Foco:** Como o FaaS funciona, configuraÃ§Ã£o e operaÃ§Ã£o do Knative no Kubernetes

---

## âš™ï¸ O que Ã© Function as a Service (FaaS)

**Function as a Service (FaaS)** Ã© um modelo de computaÃ§Ã£o serverless onde:

- ğŸ¯ **ExecuÃ§Ã£o orientada a eventos** - FunÃ§Ãµes sÃ£o invocadas por eventos especÃ­ficos
- âš¡ **Sem gerenciamento de infraestrutura** - Plataforma abstrai completamente os servidores
- ğŸ’° **Modelo de cobranÃ§a por uso** - Pague apenas pelo tempo de execuÃ§Ã£o e nÃºmero de invocaÃ§Ãµes
- ğŸ”„ **Auto-scaling** - Escala automaticamente de 0 atÃ© milhares de instÃ¢ncias
- ğŸš€ **Foco no cÃ³digo** - Desenvolvedor escreve apenas a lÃ³gica de negÃ³cio

### CaracterÃ­sticas Principais

- **Cold Start vs Warm Start**: Primeira execuÃ§Ã£o pode ter latÃªncia maior
- **Stateless**: FunÃ§Ãµes nÃ£o mantÃªm estado entre execuÃ§Ãµes
- **Timeouts**: Limites de tempo de execuÃ§Ã£o (geralmente 5-15 minutos)
- **Tamanho do cÃ³digo**: LimitaÃ§Ãµes de memÃ³ria e tamanho do pacote

### Casos de Uso Ideais

âœ… Processamento de imagens/vÃ­deos sob demanda  
âœ… APIs REST leves e rÃ¡pidas  
âœ… Processamento de eventos (filas, streams)  
âœ… Webhooks e integraÃ§Ãµes  
âœ… TransformaÃ§Ã£o de dados  
âœ… Tarefas agendadas (cron jobs)

ğŸ“Š **Exemplo PrÃ¡tico:**  
Um serviÃ§o que consulte a base/api de endereÃ§os **apenas quando necessÃ¡rio** â€” sem manter servidores ativos 24/7, economizando recursos e custos.

---

## ğŸ’¡ Problemas que o FaaS Resolve

### Antes do FaaS (Modelo Tradicional)

âŒ **ProvisÃ£o e gerenciamento de servidores** - Time gasto com infraestrutura  
âŒ **Ociosidade de recursos** - Servidores ativos mesmo sem requisiÃ§Ãµes  
âŒ **Custos fixos altos** - Pagamento contÃ­nuo independente de uso  
âŒ **Escalabilidade manual** - NecessÃ¡rio planejamento e intervenÃ§Ã£o humana  
âŒ **Tempo de deploy lento** - Provisionamento de infra leva tempo  
âŒ **Complexidade operacional** - ManutenÃ§Ã£o, patches, seguranÃ§a

### Com FaaS

âœ… **Zero infraestrutura** - Foco total no cÃ³digo de negÃ³cio  
âœ… **Economia de custos** - Pague apenas pelo que usar  
âœ… **Escalabilidade automÃ¡tica** - De 0 a milhares de instÃ¢ncias em segundos  
âœ… **Deploy rÃ¡pido** - Minutos do cÃ³digo Ã  produÃ§Ã£o  
âœ… **OperaÃ§Ãµes simplificadas** - Plataforma gerencia tudo automaticamente  
âœ… **Alta disponibilidade** - RedundÃ¢ncia e failover automÃ¡ticos


---

## â˜ï¸ Como os Provedores de Cloud Implementam FaaS

### AWS Lambda

**Arquitetura:**
- Runtime baseado em containers (Firecracker microVMs)
- Layers para dependÃªncias compartilhadas
- Integration com 200+ serviÃ§os AWS
- Suporte a 15+ linguagens (incluindo Java, Python, Node.js, Go, .NET)

**CaracterÃ­sticas:**
- Cold start: ~100ms-3s (dependendo da runtime)
- Memory: 128 MB a 10 GB
- Timeout: 15 minutos
- ConcorrÃªncia: atÃ© 1000 execuÃ§Ãµes simultÃ¢neas por funÃ§Ã£o

**Quando usar:**
- Ecossistema AWS completo
- IntegraÃ§Ã£o nativa com S3, DynamoDB, API Gateway
- Necessidade de VPC integration

---

### Azure Functions

**Arquitetura:**
- Runtime baseado em .NET Core (open source)
- Hosting plans: Consumption, Premium, Dedicated
- IntegraÃ§Ã£o com Logic Apps e Event Grid
- Durable Functions para workflows complexos

**CaracterÃ­sticas:**
- Cold start: ~200ms-2s
- Memory: 128 MB a 3.5 GB (Consumption plan)
- Timeout: 10 minutos (Consumption), ilimitado (Premium)
- Suporte a triggers HTTP, Timer, Queue, Blob, Event Hubs

**Quando usar:**
- EstÃ¡ no ecossistema Microsoft/Azure
- Precisa de integraÃ§Ã£o com Logic Apps
- Desenvolvimento em .NET/C#

---

### Google Cloud Functions

**Arquitetura:**
- Runtime baseado em containers (Cloud Run internamente)
- GeraÃ§Ã£o 2 com Cloud Run (melhor performance)
- IntegraÃ§Ã£o com Firebase, Cloud Pub/Sub
- Buildpacks para deployment

**CaracterÃ­sticas:**
- Cold start: ~100ms-1s (Gen 2)
- Memory: 128 MB a 8 GB
- Timeout: 60 minutos (Gen 2)
- Escala atÃ© 1000 instÃ¢ncias por funÃ§Ã£o

**Quando usar:**
- EstÃ¡ no ecossistema Google Cloud
- Precisa de baixa latÃªncia e cold start rÃ¡pido
- IntegraÃ§Ã£o com Firebase

---

### ComparaÃ§Ã£o: Cloud vs On-Premise

| Aspecto | Cloud (AWS/Azure/GCP) | On-Premise (Knative) |
|---------|----------------------|----------------------|
| **Setup** | ConfiguraÃ§Ã£o imediata | Requer cluster Kubernetes |
| **Custo** | Pay-per-use | Infraestrutura prÃ³pria |
| **Portabilidade** | Vendor lock-in | Multi-cloud, portÃ¡vel |
| **CustomizaÃ§Ã£o** | Limitada | Total controle |
| **Compliance** | Dependente do provider | Controle total dos dados |
| **Cold Start** | Otimizado pelo provider | Depende da configuraÃ§Ã£o |

---

## ğŸ§  Knative: Serverless para Kubernetes

### O que Ã© Knative?

**Knative** Ã© uma plataforma open-source da **CNCF (Cloud Native Computing Foundation)** que adiciona componentes serverless ao Kubernetes, permitindo:

- ğŸš€ Deploy de funÃ§Ãµes e aplicaÃ§Ãµes serverless
- ğŸ“ˆ Auto-scaling baseado em mÃ©tricas (incluindo scale-to-zero)
- ğŸ”„ Gerenciamento de trÃ¡fego e versÃµes
- ğŸ“¡ Sistema de eventos para arquitetura event-driven

### Por que Knative?

âœ… **Open Source** - Sem vendor lock-in  
âœ… **Portabilidade** - Roda em qualquer Kubernetes (cloud ou on-premise)  
âœ… **PadrÃ£o da indÃºstria** - Mantido pela CNCF, usado por grandes empresas  
âœ… **Flexibilidade** - Controle total sobre a infraestrutura  
âœ… **IntegraÃ§Ã£o nativa** - Funciona com ferramentas Kubernetes existentes

### Componentes Principais

#### 1. **Knative Serving** (Core do Serverless)

Gerencia o ciclo de vida das aplicaÃ§Ãµes serverless:

- **Knative Service (KSVC)**: Recurso principal que gerencia o deploy
- **Configuration**: VersÃµes da aplicaÃ§Ã£o
- **Revision**: Snapshot imutÃ¡vel de uma configuraÃ§Ã£o
- **Route**: Roteamento de trÃ¡fego entre revisÃµes
- **Autoscaler**: Escala baseado em mÃ©tricas (concorrÃªncia, requisiÃ§Ãµes)

**Fluxo de Funcionamento:**
```
Request â†’ Kourier Ingress â†’ Knative Service â†’ Revision â†’ Pods
                                                      â†“
                                            Autoscaler (scale 0-N)
```

#### 2. **Knative Eventing** (Event-Driven)

Permite funÃ§Ãµes reagirem a eventos de mÃºltiplas fontes:

- **Sources**: Origem dos eventos (Kafka, GitHub, S3, etc.)
- **Brokers/Channels**: Camada de mensageria
- **Triggers**: Conecta eventos a funÃ§Ãµes
- **CloudEvents**: PadrÃ£o CNCF para eventos

**Casos de uso:**
- Webhooks
- IntegraÃ§Ã£o com filas (Kafka, RabbitMQ)
- Processamento assÃ­ncrono
- Arquitetura event-driven

### Arquitetura Knative no Kubernetes

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Knative Control Plane                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  â”‚   Serving    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Eventing   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  Controller  â”‚         â”‚  Controller  â”‚       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                             â”‚
â”‚                           â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Knative Services (Pods)               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚  â”‚ Function â”‚  â”‚ Function â”‚  â”‚ Function â”‚        â”‚   â”‚
â”‚  â”‚  â”‚   Pod    â”‚  â”‚   Pod    â”‚  â”‚   Pod    â”‚        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                             â”‚
â”‚                           â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Kourier Ingress (Load Balancer)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Cliente     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Escalabilidade no Knative

**Scale-to-Zero:**
- ApÃ³s perÃ­odo de inatividade (default: 30s), pods sÃ£o removidos
- Primeira requisiÃ§Ã£o apÃ³s inatividade aciona "cold start"
- Reduz custos drasticamente

**Scale-Up:**
- Baseado em mÃ©tricas de concorrÃªncia e requisiÃ§Ãµes por segundo
- Pode escalar de 0 a N pods em segundos
- ConfigurÃ¡vel via annotations

**Exemplo de configuraÃ§Ã£o:**
```yaml
annotations:
  autoscaling.knative.dev/minScale: "0"  # Permite scale-to-zero
  autoscaling.knative.dev/maxScale: "10" # Limite mÃ¡ximo
  autoscaling.knative.dev/target: "10"   # RequisiÃ§Ãµes por pod (configurado para demonstraÃ§Ã£o)
```

---

## ğŸ§° ConfiguraÃ§Ã£o do Knative em Cluster On-Premise

> **Perspectiva de Infraestrutura:** Passo a passo completo para instalar e configurar o Knative

### PrÃ©-requisitos

Antes de instalar o Knative, certifique-se de ter:

âœ… **Kubernetes cluster** funcionando (v1.25+)  
âœ… **kubectl** configurado e com acesso ao cluster  
âœ… **Istio** ou **Kourier** para ingress (usaremos Kourier)  
âœ… **MÃ©tricas** (Metrics Server) para autoscaling  
âœ… **DNS** configurado ou usar nip.io para desenvolvimento

### Passo 1: Verificar o Cluster Kubernetes

```bash
# Verificar versÃ£o do cluster
kubectl version --short

# Verificar nÃ³s do cluster
kubectl get nodes

# Verificar se o Metrics Server estÃ¡ instalado (necessÃ¡rio para autoscaling)
kubectl top nodes
```

### Passo 2: Instalar Knative Serving CRDs

**Custom Resource Definitions** definem os recursos personalizados do Knative:

```bash
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.19.7/serving-crds.yaml
```

**O que isso instala:**
- `services.serving.knative.dev` - Knative Services
- `configurations.serving.knative.dev` - Configurations
- `revisions.serving.knative.dev` - Revisions
- `routes.serving.knative.dev` - Routes

**Verificar instalaÃ§Ã£o:**
```bash
kubectl get crd | grep knative
```

### Passo 3: Instalar Knative Serving Core

Instala os controladores que gerenciam os recursos Knative:

```bash
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.19.7/serving-core.yaml
```

**Verificar se os pods estÃ£o rodando:**
```bash
kubectl get pods -n knative-serving
# Deve mostrar pods: controller, autoscaler, networking-istio, webhook
```

### Passo 4: Instalar Kourier (Ingress Controller)

**Kourier** Ã© um ingress controller leve para Knative (alternativa ao Istio):

```bash
kubectl apply -f https://github.com/knative-extensions/net-kourier/releases/download/knative-v1.19.6/kourier.yaml
```

**Verificar instalaÃ§Ã£o:**
```bash
kubectl get pods -n kourier-system
# Deve mostrar: 3scale-kourier-control e 3scale-kourier-gateway
```

### Passo 5: Configurar DomÃ­nio PadrÃ£o

Para desenvolvimento local, vamos usar **nip.io** que resolve IPs automaticamente:

```bash
# Instalar configuraÃ§Ã£o de domÃ­nio padrÃ£o
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.19.7/serving-default-domain.yaml

# Configurar domÃ­nio local (127.0.0.1.nip.io)
kubectl patch configmap/config-domain \
  --namespace knative-serving \
  --type merge \
  --patch '{"data": {"127.0.0.1.nip.io": ""}}'
```

**Para produÃ§Ã£o:** Configure seu prÃ³prio domÃ­nio DNS apontando para o IP do ingress.

### Passo 6: Configurar Kourier como Ingress PadrÃ£o

```bash
kubectl patch configmap/config-network \
  --namespace knative-serving \
  --type merge \
  --patch '{"data":{"ingress-class":"kourier.ingress.networking.knative.dev"}}'
```

### Passo 7: Instalar HPA (Horizontal Pod Autoscaler)

HPA permite autoscaling baseado em CPU/memÃ³ria:

```bash
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.19.7/serving-hpa.yaml
```

### Passo 8: Verificar InstalaÃ§Ã£o Completa

```bash
# Verificar todos os componentes
kubectl get pods --all-namespaces | grep -E "knative|kourier"

# Verificar se Knative estÃ¡ pronto
kubectl get knative
```

### Passo 9: Configurar Port Forward (Desenvolvimento Local)

Para acessar serviÃ§os localmente sem configurar LoadBalancer:

```bash
# Em um terminal separado, fazer port-forward do Kourier
kubectl port-forward --namespace kourier-system service/kourier 8080:80
```

Agora vocÃª pode acessar serviÃ§os em: `http://<servico>.<namespace>.127.0.0.1.nip.io:8080`

### Resumo da InstalaÃ§Ã£o

ApÃ³s completar todos os passos, vocÃª terÃ¡:

âœ… **Knative Serving** instalado e configurado  
âœ… **Kourier** como ingress controller  
âœ… **HPA** para autoscaling baseado em mÃ©tricas  
âœ… **DomÃ­nio** configurado para desenvolvimento  
âœ… **Cluster** pronto para receber funÃ§Ãµes serverless

---

## ğŸ—ï¸ Arquitetura e Escalabilidade: Como Funciona Internamente

### Fluxo de RequisiÃ§Ã£o no Knative

```text
1. RequisiÃ§Ã£o HTTP
   â†“
2. Kourier Ingress (Load Balancer)
   â†“
3. Knative Route (Roteamento)
   â†“
4. Revision Check (Verifica se existe pod ativo)
   â†“
5a. Se pod existe â†’ Roteia para o pod
5b. Se nÃ£o existe â†’ Aciona Autoscaler â†’ Cria pod â†’ Cold Start
   â†“
6. FunÃ§Ã£o executa
   â†“
7. Resposta retornada
```

### Componentes de Autoscaling

#### KPA (Knative Pod Autoscaler)
- MÃ©trica principal: **ConcorrÃªncia** (requisiÃ§Ãµes simultÃ¢neas por pod)
- Target default: 100 requisiÃ§Ãµes concorrentes por pod
- Reativa: Escala baseado em requisiÃ§Ãµes ativas

#### HPA (Horizontal Pod Autoscaler) - Alternativa
- MÃ©trica principal: **CPU/MemÃ³ria**
- ConfigurÃ¡vel via annotations
- Mais apropriado para workloads CPU-intensive

### Como o Scale-to-Zero Funciona

1. **PerÃ­odo de Inatividade**: ApÃ³s 30 segundos sem requisiÃ§Ãµes
2. **Queue Proxy**: MantÃ©m um "queue-proxy" que intercepta requisiÃ§Ãµes
3. **Activator**: Primeira requisiÃ§Ã£o apÃ³s inatividade vai para o Activator
4. **Wake-up**: Activator acorda um pod (ou cria novo)
5. **Request Buffering**: RequisiÃ§Ãµes sÃ£o bufferizadas durante cold start

### MÃ©tricas Coletadas

O Knative coleta mÃ©tricas atravÃ©s do **Queue Proxy** (sidecar em cada pod):

- **Concurrency**: RequisiÃ§Ãµes simultÃ¢neas
- **RPS** (Requests Per Second): Taxa de requisiÃ§Ãµes
- **Latency**: Tempo de resposta (p50, p90, p99)
- **Pod Count**: NÃºmero de pods ativos

### ConfiguraÃ§Ãµes Importantes

```yaml
# ConfiguraÃ§Ã£o Global (ConfigMap)
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-autoscaler
  namespace: knative-serving
data:
  scale-to-zero-grace-period: "30s"        # Tempo antes de scale-to-zero
  stable-window: "60s"                      # Janela para estabilizar mÃ©tricas
  panic-window-percentage: "10.0"           # Janela de pÃ¢nico (scale rÃ¡pido)
  max-scale-up-rate: "1000.0"               # MÃ¡xima taxa de scale-up
```

### Observabilidade na Camada de Infraestrutura

**Monitorar recursos Knative:**

```bash
# Ver status de todos os serviÃ§os
kubectl get ksvc --all-namespaces

# Ver revisÃµes e seu trÃ¡fego
kubectl get revisions -n cep

# Ver configuraÃ§Ãµes de autoscaling
kubectl get podautoscaler -n cep

# Ver mÃ©tricas do autoscaler
kubectl logs -n knative-serving -l app=autoscaler --tail=100

# Ver eventos do Knative
kubectl get events -n cep --sort-by='.lastTimestamp'
```

**Componentes para monitorar:**

- `controller`: Gerencia o ciclo de vida dos recursos
- `autoscaler`: Calcula e aplica scaling decisions
- `activator`: Gerencia cold starts e scale-to-zero
- `webhook`: ValidaÃ§Ã£o e mutaÃ§Ã£o de recursos
- `queue-proxy`: Sidecar que coleta mÃ©tricas em cada pod

---

## ğŸ”„ TransiÃ§Ã£o: Da Infraestrutura ao Desenvolvimento

Agora que entendemos **como o FaaS funciona** e **como configurar o Knative** no Kubernetes, vamos mudar para a **perspectiva do desenvolvedor**:

- âœ… Infraestrutura configurada e pronta
- âœ… Knative instalado e funcionando
- âœ… Cluster Kubernetes operacional

**PrÃ³ximo passo:** Criar e deployar uma funÃ§Ã£o real!

---

## ğŸ‘¨â€ğŸ’» PARTE 2: VISÃƒO DO DESENVOLVEDOR

> **Foco:** Criar funÃ§Ãµes, realizar deploy e observar o serverless em funcionamento

**O que vamos fazer:**
1. Criar uma funÃ§Ã£o Spring Boot usando templates
2. Implementar a lÃ³gica de negÃ³cio
3. Fazer build e deploy da funÃ§Ã£o
4. Testar e validar o funcionamento
5. Observar escalabilidade automÃ¡tica em aÃ§Ã£o

---

## ğŸ§± Arquitetura da DemonstraÃ§Ã£o

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Desenvolvedor/CI/CD                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ 1. CÃ³digo Spring Boot Function
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Spring Cloud Function Application              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  @Bean Function<Message<String>, String> cep()       â”‚   â”‚
â”‚  â”‚  - Recebe CEP via HTTP POST                          â”‚   â”‚
â”‚  â”‚  - Consulta API ViaCEP                               â”‚   â”‚
â”‚  â”‚  - Retorna JSON com dados do endereÃ§o                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ 2. Build (Maven + Docker)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Container Image (Docker Hub)                   â”‚
â”‚              diogocarvalho/faas-demo:latest                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ 3. Deploy (kn CLI ou kubectl)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubernetes Cluster (On-Premise)                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Knative Service (KSVC)                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  Configuration â†’ Revision â†’ Deployment       â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚                      â”‚                               â”‚   â”‚
â”‚  â”‚                      â–¼                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  Autoscaler (KPA/HPA)                        â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - Scale: 0 â†’ N pods                         â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - Baseado em concorrÃªncia/requisiÃ§Ãµes       â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â”‚                                      â”‚
â”‚                      â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Kourier Ingress Controller                 â”‚   â”‚
â”‚  â”‚  - ExposiÃ§Ã£o HTTP/HTTPS                              â”‚   â”‚
â”‚  â”‚  - Load Balancing                                    â”‚   â”‚
â”‚  â”‚  - Domain: api.cep.127.0.0.1.nip.io                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ 4. HTTP Request
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Cliente (curl/browser)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â˜• Criando a FunÃ§Ã£o Spring Boot

### PrÃ©-requisitos para Desenvolvimento

```bash
# Instalar Knative Func CLI
# macOS
brew install knative-sandbox/kn-plugins/func

# Linux
wget https://github.com/knative/func/releases/latest/download/func_linux_amd64
chmod +x func_linux_amd64
sudo mv func_linux_amd64 /usr/local/bin/func

# Verificar instalaÃ§Ã£o
func version
```

### Passo 1: Criar Projeto da FunÃ§Ã£o

O Knative Func CLI oferece templates prÃ©-configurados:

```bash
# Verificar templates disponÃ­veis
kn func create --help

# Criar funÃ§Ã£o Spring Boot
kn func create -l springboot cep-function-springboot

# Navegar para o diretÃ³rio
cd cep-function-springboot
```

**Templates disponÃ­veis:**
- `http`: FunÃ§Ã£o exposta via HTTP (ideal para APIs REST)
- `cloudevents`: FunÃ§Ã£o que processa eventos CloudEvents
- `springboot`: Template completo com Spring Boot e Spring Cloud Function

### Passo 2: Estrutura do Projeto

ApÃ³s criar, vocÃª terÃ¡:

```
cep-function-springboot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â”‚   â””â”€â”€ functions/
â”‚   â”‚   â”‚       â””â”€â”€ CloudFunctionApplication.java
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ application.properties
â”‚   â””â”€â”€ test/
â”œâ”€â”€ pom.xml
â”œâ”€â”€ func.yaml          # ConfiguraÃ§Ã£o do Knative Func
â””â”€â”€ Dockerfile         # Opcional (gerado automaticamente)
```

### Passo 3: Implementar a LÃ³gica da FunÃ§Ã£o

Edite `src/main/java/functions/CloudFunctionApplication.java`:

```java
package functions;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.messaging.Message;
import org.springframework.web.client.RestTemplate;

import java.util.function.Function;

@SpringBootApplication
public class CloudFunctionApplication {

  public static void main(String[] args) {
    SpringApplication.run(CloudFunctionApplication.class, args);
  }

  @Bean
  public Function<Message<String>, String> cep() {
    return (inputMessage) -> {
      String cep = inputMessage.getPayload();
      
      // ValidaÃ§Ã£o bÃ¡sica do CEP (8 dÃ­gitos)
      if (cep == null || !cep.matches("\\d{8}")) {
        return "{\"erro\": \"CEP invÃ¡lido. Use 8 dÃ­gitos.\"}";
      }
      
      // Consulta API ViaCEP
      String apiUrl = "https://viacep.com.br/ws/" + cep + "/json/";
      RestTemplate restTemplate = new RestTemplate();
      
      try {
        String resultado = restTemplate.getForObject(apiUrl, String.class);
        
        // Verifica se o CEP foi encontrado
        if (resultado != null && resultado.contains("\"erro\"")) {
          return "{\"erro\": \"CEP nÃ£o encontrado.\"}";
        }
        
        return resultado;
      } catch (Exception e) {
        return "{\"erro\": \"Erro ao consultar API: " + e.getMessage() + "\"}";
      }
    };
  }
}
```

**ExplicaÃ§Ã£o:**
- `@SpringBootApplication`: ConfiguraÃ§Ã£o automÃ¡tica do Spring Boot
- `Function<Message<String>, String>`: Interface funcional do Spring Cloud Function
- `Message<String>`: Permite acesso a headers e payload
- A funÃ§Ã£o serÃ¡ exposta automaticamente como endpoint HTTP `/cep`

### Passo 4: Configurar func.yaml

O arquivo `func.yaml` define como a funÃ§Ã£o serÃ¡ construÃ­da e deployada:

```yaml
specVersion: 0.36.0
name: cep
runtime: springboot
registry: diogocarvalho/faas-demo  # Seu registry Docker
image: index.docker.io/diogocarvalho/faas-demo/cep:latest
build:
  builder: pack
  buildEnvs:
    - name: BP_NATIVE_IMAGE
      value: "false"  # true para GraalVM native image
    - name: BP_JVM_VERSION
      value: "21"
deploy:
  healthEndpoints:
    liveness: /actuator/health
    readiness: /actuator/health
```

### Passo 5: Testar Localmente

```bash
# Executar localmente (requer Docker)
func run

# Em outro terminal, testar
curl -X POST http://localhost:8080/cep \
  -H "Content-Type: text/plain" \
  -d "71691000"
```

---

## ğŸ³ Build da Imagem Docker

### OpÃ§Ã£o 1: Usando Dockerfile Manual

Se preferir controle total, crie um `Dockerfile`:

```dockerfile
FROM --platform=linux/arm64 alpine:3.19
# FROM --platform=linux/amd64 alpine:3.19

# Instalar bibliotecas necessÃ¡rias para binÃ¡rios nativos
RUN apk add --no-cache libc6-compat zlib

# Copiar o binÃ¡rio nativo (jÃ¡ buildado localmente para Linux)
COPY target/function /app/function

# Tornar executÃ¡vel
RUN chmod +x /app/function

# Expor porta padrÃ£o do Spring Boot
EXPOSE 8080

# Usar usuÃ¡rio nÃ£o-root (seguranÃ§a)
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
USER appuser

# Executar o binÃ¡rio nativo
ENTRYPOINT ["/app/function"]

```

**Build e push manual:**

Por tratar-se de um ambiente local MacOS ARM64, temos que buildar a imagem para linux, com isso, criei o script shell abaixo para facilitar este procedimento:

```bash
#!/bin/bash

# Script para executar Maven dentro do Docker (como se fosse local)
# Permite usar comandos Maven normalmente, mas roda dentro do container

set -e

# Verificar se Docker estÃ¡ rodando
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker nÃ£o estÃ¡ rodando. Por favor, inicie o Docker e tente novamente."
    exit 1
fi

# DiretÃ³rio do projeto
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Detectar plataforma
PLATFORM="${DOCKER_PLATFORM:-linux/arm64}"

# Executar Maven dentro do container Docker
# Monta o diretÃ³rio do projeto como volume, entÃ£o as mudanÃ§as sÃ£o preservadas
docker run --rm -it \
  --platform "$PLATFORM" \
  -v "$PROJECT_DIR:/build" \
  -w /build \
  -v "$HOME/.m2:/root/.m2" \
  ghcr.io/graalvm/graalvm-community:latest \
  bash -c "
    # Instalar native-image se nÃ£o estiver instalado
    if ! command -v native-image &> /dev/null; then
      echo 'ğŸ“¦ Instalando native-image...'
      gu install native-image
    fi
    
    # Executar o comando Maven passado como argumento
    ./mvnw \"\$@\"
  " -- "$@"
```

```bash
# Compilar projeto
./build.sh -P native native:compile -DskipTests

#Build e Push da imagem
docker build -t diogocarvalho/faas-demo:latest . && docker push diogocarvalho/faas-demo:latest
```

### OpÃ§Ã£o 2: Usando Knative Func CLI (Recomendado)

O CLI gerencia build e push automaticamente:

```bash
# Configurar registry (se ainda nÃ£o fez)
export FUNC_REGISTRY=docker.io/diogocarvalho/faas-demo

# Build usando Cloud Native Buildpacks (pack)
func build

# Ou build + push + deploy em um comando
func deploy --registry docker.io/diogocarvalho/faas-demo
```

---

## ğŸ—ï¸ Deploy no Cluster Knative

### MÃ©todo 1: Usando Knative Func CLI (Mais Simples)

```bash
# Deploy direto (faz build + push + deploy)
func deploy \
  --registry docker.io/diogocarvalho/faas-demo \
  --namespace cep \
  --verbose

# Ou se jÃ¡ configurou FUNC_REGISTRY
func deploy --namespace cep
```

### MÃ©todo 2: Usando kn CLI (Knative CLI)

```bash
# Criar namespace (se nÃ£o existir)
kubectl create namespace cep

# Deploy do serviÃ§o
kn service create api \
  --image docker.io/diogocarvalho/faas-demo:latest \
  --port 8080 \
  --namespace cep \
  --env JAVA_OPTS="-Xmx512m" \
  --annotation autoscaling.knative.dev/minScale="0" \
  --annotation autoscaling.knative.dev/maxScale="10" \
  --annotation autoscaling.knative.dev/target="10"

# Ou usar arquivo de configuraÃ§Ã£o
kn service apply -f service.yaml
```

### MÃ©todo 3: Usando kubectl (YAML)

Criar arquivo `service.yaml`:

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: api
  namespace: cep
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "0"
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/target: "10"
    spec:
      containers:
      - image: docker.io/diogocarvalho/faas-demo:latest
        ports:
        - containerPort: 8080
        env:
        - name: JAVA_OPTS
          value: "-Xmx512m"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
```

Aplicar:
```bash
kubectl apply -f service.yaml
```

### Verificar Deploy

```bash
# Verificar status do serviÃ§o
kn service list -n cep

# Ver detalhes
kn service describe api -n cep

# Ver URL do serviÃ§o
kn service list -n cep -o url

# Ver pods (inicialmente pode estar 0 - scale-to-zero)
kubectl get pods -n cep -w
```

---

## ğŸ§ª Testando a FunÃ§Ã£o

### Obter URL do ServiÃ§o

```bash
# Usando kn CLI
kn service describe api -n cep | grep URL

# Ou verificar via kubectl
kubectl get ksvc api -n cep -o jsonpath='{.status.url}'
```

**Exemplo de URL:** `http://api.cep.127.0.0.1.nip.io`

### Testar a FunÃ§Ã£o

```bash
# Teste bÃ¡sico
curl -X POST \
  http://api.cep.127.0.0.1.nip.io \
  -H "Content-Type: text/plain" \
  -d "71691058"

# Com port-forward (se necessÃ¡rio)
kubectl port-forward -n kourier-system service/kourier 8080:80

curl -X POST \
  http://api.cep.127.0.0.1.nip.io:8080 \
  -H "Content-Type: text/plain" \
  -d "71691058"
```

**Resposta esperada:**
```json
{
  "cep": "71691-058",
  "logradouro": "SQN 107 Bloco H",
  "complemento": "",
  "bairro": "Asa Norte",
  "localidade": "BrasÃ­lia",
  "uf": "DF",
  "ibge": "5300108",
  "gia": "",
  "ddd": "61",
  "siafi": "9701"
}
```

### Testar CenÃ¡rios

```bash
# CEP vÃ¡lido
curl -X POST http://api.cep.127.0.0.1.nip.io \
  -H "Content-Type: text/plain" \
  -d "01310100"

# CEP invÃ¡lido
curl -X POST http://api.cep.127.0.0.1.nip.io \
  -H "Content-Type: text/plain" \
  -d "123"

# CEP inexistente
curl -X POST http://api.cep.127.0.0.1.nip.io \
  -H "Content-Type: text/plain" \
  -d "00000000"
```

---

## ğŸ“ˆ Serverless em AÃ§Ã£o: Observando o Comportamento na PrÃ¡tica

> **Perspectiva do Desenvolvedor:** Ver na prÃ¡tica como a funÃ§Ã£o escala automaticamente

### DemonstraÃ§Ã£o 1: Observando o Scale-to-Zero

**Objetivo:** Ver como a funÃ§Ã£o escala para zero apÃ³s inatividade

**Passo 1: Verificar estado inicial (zero pods)**

Em um terminal, monitore os pods:

```bash
# Terminal 1: Monitorar pods em tempo real
watch -n 1 'kubectl get pods -n cep'
```

**Passo 2: Fazer primeira requisiÃ§Ã£o (Cold Start)**

Em outro terminal, faÃ§a uma requisiÃ§Ã£o e meÃ§a o tempo:

```bash
# Terminal 2: RequisiÃ§Ã£o que vai acionar o cold start
echo "=== Primeira requisiÃ§Ã£o (Cold Start) ==="
time curl -X POST http://api.cep.127.0.0.1.nip.io:8080 \
  -H "Content-Type: text/plain" \
  -d "71691058"
```

**O que observar:**
- â±ï¸ **Tempo de resposta:** Pode levar 15-30 segundos na primeira requisiÃ§Ã£o
- ğŸ“¦ **Pod sendo criado:** No Terminal 1, vocÃª verÃ¡ o pod aparecer
- ğŸ”„ **Status do pod:** Iniciando como "Pending" â†’ "ContainerCreating" â†’ "Running"

**Passo 3: Fazer requisiÃ§Ãµes subsequentes (Warm)**

```bash
# Terminal 2: RequisiÃ§Ãµes subsequentes serÃ£o mais rÃ¡pidas
echo "=== Segunda requisiÃ§Ã£o (Warm) ==="
time curl -X POST http://api.cep.127.0.0.1.nip.io:8080 \
  -H "Content-Type: text/plain" \
  -d "01310100"

echo "=== Terceira requisiÃ§Ã£o (Warm) ==="
time curl -X POST http://api.cep.127.0.0.1.nip.io:8080 \
  -H "Content-Type: text/plain" \
  -d "20040020"
```

**O que observar:**
- âš¡ **LatÃªncia reduzida:** RequisiÃ§Ãµes subseqÃ¼entes sÃ£o muito mais rÃ¡pidas (< 1s)
- ğŸ“Š **Pod ativo:** Pod permanece "Running" enquanto hÃ¡ trÃ¡fego

**Passo 4: Aguardar scale-to-zero**

```bash
# Aguarde aproximadamente 30-60 segundos sem fazer requisiÃ§Ãµes
# No Terminal 1, vocÃª verÃ¡ o pod ser removido automaticamente
```

**O que observar:**
- â° **ApÃ³s ~30 segundos:** Pod muda para "Terminating"
- ğŸ—‘ï¸ **Pod removido:** Pod desaparece completamente
- âœ… **Zero recursos:** Nenhum pod ativo = zero custo

### DemonstraÃ§Ã£o 2: Observando o Auto-Scaling (Scale-Up)

**Objetivo:** Ver como a funÃ§Ã£o escala automaticamente sob carga

**PreparaÃ§Ã£o: Abrir 3 terminais**

**Terminal 1: Monitorar pods**
```bash
watch -n 1 'kubectl get pods -n cep -o wide'
```

**Terminal 2: Monitorar serviÃ§os Knative**
```bash
watch -n 1 'kn service list -n cep'
```

**Terminal 3: Gerar carga**

Instalar ferramenta de load testing:

```bash
# macOS
brew install hey

# Linux
wget https://hey-release.s3.us-east-2.amazonaws.com/hey_linux_amd64
chmod +x hey_linux_amd64
sudo mv hey_linux_amd64 /usr/local/bin/hey
```

**Executar teste de carga:**

No Terminal 3, execute:

```bash
# Teste 1: 50 requisiÃ§Ãµes, 5 simultÃ¢neas (escala lenta)
echo "=== Teste 1: Carga moderada ==="
hey -n 50 -c 5 -m POST \
  -H "Content-Type: text/plain" \
  -d "71691058" \
  http://api.cep.127.0.0.1.nip.io:8080

# Aguardar alguns segundos...

# Teste 2: 200 requisiÃ§Ãµes, 20 simultÃ¢neas (escala rÃ¡pida)
echo "=== Teste 2: Carga alta ==="
hey -n 200 -c 20 -m POST \
  -H "Content-Type: text/plain" \
  -d "71691058" \
  http://api.cep.127.0.0.1.nip.io:8080
```

**O que observar nos terminais:**

**Terminal 1 (Pods):**
- ğŸ“ˆ **Escala crescendo:** Pods sendo criados rapidamente
- ğŸ”¢ **MÃºltiplos pods:** VÃ¡rios pods em "Running"
- âš¡ **DistribuiÃ§Ã£o:** RequisiÃ§Ãµes distribuÃ­das entre pods

**Terminal 2 (ServiÃ§os):**
- ğŸ“Š **Status:** URL do serviÃ§o permanece ativa
- ğŸ¯ **RevisÃµes:** Nova revisÃ£o pode aparecer se atualizar

**Terminal 3 (Resultados):**
- â±ï¸ **LatÃªncia:** Tempo mÃ©dio de resposta
- ğŸ“ˆ **Throughput:** RequisiÃ§Ãµes por segundo
- âœ… **Success rate:** Taxa de sucesso

### Resumo da DemonstraÃ§Ã£o

**O que foi observado:**
1. âœ… **Scale-to-Zero:** FunÃ§Ã£o escalou para zero apÃ³s inatividade
2. âœ… **Cold Start:** Primeira requisiÃ§Ã£o demorou mais (pod sendo criado)
3. âœ… **Warm Requests:** RequisiÃ§Ãµes subsequentes muito mais rÃ¡pidas
4. âœ… **Auto-Scaling:** FunÃ§Ã£o escalou automaticamente sob carga
5. âœ… **Zero Config:** Tudo automÃ¡tico, sem intervenÃ§Ã£o manual

**BenefÃ­cios para o desenvolvedor:**
- ğŸš€ **Deploy simples:** Apenas `func deploy` ou `kn service create`
- âš¡ **Performance automÃ¡tica:** Escalabilidade gerenciada pela plataforma
- ğŸ’° **Custo eficiente:** Paga apenas quando hÃ¡ requisiÃ§Ãµes
- ğŸ”§ **Foco no cÃ³digo:** Zero preocupaÃ§Ã£o com infraestrutura

---

## âœ… ConclusÃµes

### ğŸ“ Perspectiva de Infraestrutura

âœ… **Knative Ã© uma soluÃ§Ã£o robusta para serverless on-premise**
- Projeto CNCF maduro e estÃ¡vel
- Sem vendor lock-in, total portabilidade
- IntegraÃ§Ã£o nativa com Kubernetes
- Escalabilidade automÃ¡tica baseada em mÃ©tricas reais

âœ… **ConfiguraÃ§Ã£o e operaÃ§Ã£o sÃ£o diretas**
- InstalaÃ§Ã£o via YAML (declarativa)
- Componentes bem definidos e observÃ¡veis
- ConfiguraÃ§Ã£o flexÃ­vel para diferentes cenÃ¡rios
- Troubleshooting facilitado por mÃ©tricas nativas

âœ… **Knative complementa Kubernetes perfeitamente**
- Aproveita recursos existentes do cluster
- Funciona com ferramentas de observabilidade existentes
- Suporta diferentes ingress controllers (Kourier, Istio)
- Integra com CI/CD pipelines

### ğŸ‘¨â€ğŸ’» Perspectiva do Desenvolvedor

âœ… **FaaS simplifica significativamente o desenvolvimento**
- Foco total na lÃ³gica de negÃ³cio
- Zero preocupaÃ§Ã£o com infraestrutura
- Deploy extremamente rÃ¡pido e simples

âœ… **ExperiÃªncia de desenvolvimento otimizada**
- Templates prontos para iniciar rapidamente
- Build e deploy automatizados
- Hot reload e teste local facilitado
- Suporte a mÃºltiplas linguagens (Java, Go, Node, Python, etc.)

âœ… **Escalabilidade automÃ¡tica funciona na prÃ¡tica**
- Scale-to-zero economiza recursos
- Escala rÃ¡pida sob demanda sem intervenÃ§Ã£o
- Cold start gerenciado automaticamente
- Performance otimizada para workloads event-driven

âœ… **Produtividade aumentada**
- Deploy em minutos vs horas/dias
- Menos configuraÃ§Ã£o = menos erros
- Foco no cÃ³digo de negÃ³cio
- Ciclo de feedback mais rÃ¡pido

### BenefÃ­cios Demonstrados

| Aspecto | BenefÃ­cio |
|---------|-----------|
| **Custos** | ReduÃ§Ã£o de 60-80% em cenÃ¡rios com trÃ¡fego variÃ¡vel |
| **Deploy** | Minutos do cÃ³digo Ã  produÃ§Ã£o |
| **OperaÃ§Ãµes** | 70-90% menos tempo com infraestrutura |
| **Escalabilidade** | AutomÃ¡tica de 0 a N instÃ¢ncias |
| **ManutenÃ§Ã£o** | Zero manutenÃ§Ã£o de servidores |

### Quando Usar FaaS?

âœ… **Ideal para:**
- APIs REST leves e rÃ¡pidas
- Processamento de eventos assÃ­ncronos
- MicroserviÃ§os com trÃ¡fego variÃ¡vel
- IntegraÃ§Ãµes e webhooks
- Processamento de dados sob demanda

âŒ **NÃ£o ideal para:**
- AplicaÃ§Ãµes com estado persistente
- Workloads com processamento longo (>15 min)
- AplicaÃ§Ãµes que requerem conexÃµes persistentes
- FunÃ§Ãµes com cold start crÃ­tico (latÃªncia <100ms)

---

## ğŸ”® PrÃ³ximos Passos

### NÃ­vel 1: Explorar Knative Eventing

Implementar arquitetura event-driven:

```bash
# Instalar Knative Eventing
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.19.7/eventing-crds.yaml
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.19.7/eventing-core.yaml

# Criar funÃ§Ã£o que processa eventos
kn func create -l springboot -t cloudevents processador-eventos
```

**Casos de uso:**
- Webhooks de GitHub/GitLab
- Processamento de eventos de filas
- Arquitetura pub/sub

### NÃ­vel 2: IntegraÃ§Ã£o com Filas e Mensageria

**Kafka Integration:**
```bash
# Instalar Kafka Source para Knative
kubectl apply -f https://github.com/knative-sandbox/eventing-kafka-broker/releases/download/knative-v1.19.0/eventing-kafka-controller.yaml
```

**RabbitMQ Integration:**
- Usar Knative Eventing Sources
- Criar triggers para processar mensagens

### NÃ­vel 3: CI/CD para FunÃ§Ãµes Serverless

**Exemplo com GitHub Actions:**

```yaml
name: Deploy Function
on:
  push:
    branches: [main]
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Func CLI
        run: |
          wget https://github.com/knative/func/releases/latest/download/func_linux_amd64
          chmod +x func_linux_amd64
          sudo mv func_linux_amd64 /usr/local/bin/func
      - name: Deploy
        run: |
          func deploy --registry docker.io/diogocarvalho/faas-demo --namespace cep
```

### NÃ­vel 4: Observabilidade e Monitoramento

**Instalar Prometheus e Grafana:**

```bash
# Instalar Prometheus Operator
kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/bundle.yaml

# Configurar mÃ©tricas do Knative
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.19.7/serving-core.yaml
```

**MÃ©tricas importantes:**
- Request rate (req/s)
- LatÃªncia (p50, p95, p99)
- Cold start duration
- Pod count (escalabilidade)
- Error rate

**Dashboard Grafana:**
- Criar dashboards para visualizar mÃ©tricas
- Alertas para cold starts longos
- Monitoramento de custos (pod-hours)

### NÃ­vel 5: SeguranÃ§a e Boas PrÃ¡ticas

**Implementar:**
- Network policies para isolamento
- Secrets management (Vault/Sealed Secrets)
- Image scanning (Trivy, Snyk)
- RBAC (Role-Based Access Control)
- mTLS entre serviÃ§os (Istio)

### Recursos Adicionais

ğŸ“š **DocumentaÃ§Ã£o Oficial:**
- [Knative Documentation](https://knative.dev/docs/)
- [Spring Cloud Function](https://spring.io/projects/spring-cloud-function)
- [Knative Serving Examples](https://github.com/knative/docs/tree/main/docs/serving/samples)

ğŸ“ **Tutoriais:**
- [Knative Getting Started](https://knative.dev/docs/getting-started/)
- [Spring Cloud Function Guide](https://docs.spring.io/spring-cloud-function/docs/current/reference/html/)

ğŸ’¡ **Comunidade:**
- [Knative Slack](https://knative.slack.com/)
- [CNCF Slack](https://slack.cncf.io/)
- GitHub Discussions

---

## ğŸ› ï¸ Troubleshooting Comum

### Problema: Pod nÃ£o escala de zero

**SoluÃ§Ã£o:**
```bash
# Verificar autoscaler
kubectl get podautoscaler -n cep

# Verificar logs do autoscaler
kubectl logs -n knative-serving -l app=autoscaler

# Verificar se Metrics Server estÃ¡ funcionando
kubectl top pods -n cep
```

### Problema: Cold start muito longo

**SoluÃ§Ãµes:**
- Usar `minScale: "1"` para manter um pod warm
- Otimizar tamanho da imagem Docker
- Considerar GraalVM native image
- Reduzir dependÃªncias

### Problema: Erro de conexÃ£o ao serviÃ§o

**SoluÃ§Ã£o:**
```bash
# Verificar se Kourier estÃ¡ rodando
kubectl get pods -n kourier-system

# Verificar configuraÃ§Ã£o de domÃ­nio
kubectl get configmap config-domain -n knative-serving

# Verificar port-forward
kubectl port-forward -n kourier-system service/kourier 8080:80
```

### Problema: FunÃ§Ã£o retorna timeout

**SoluÃ§Ã£o:**
```bash
# Aumentar timeout do Knative
kn service update api \
  --namespace cep \
  --annotation timeoutSeconds="300"
```


## ğŸ™Œ Encerramento

### Resumo da ApresentaÃ§Ã£o Completa

#### ğŸ“ VisÃ£o de Infraestrutura
1. âœ… Entendemos o funcionamento do FaaS e seus componentes
2. âœ… Configuramos o Knative em um cluster Kubernetes on-premise
3. âœ… Aprendemos sobre arquitetura, escalabilidade e componentes internos
4. âœ… Monitoramos e observamos o comportamento do sistema

#### ğŸ‘¨â€ğŸ’» VisÃ£o do Desenvolvedor
1. âœ… Criamos uma funÃ§Ã£o serverless com Spring Boot
2. âœ… Implementamos a lÃ³gica de negÃ³cio (consulta de CEP)
3. âœ… Realizamos build e deploy da funÃ§Ã£o no cluster
4. âœ… Testamos e validamos o funcionamento
5. âœ… Observamos escalabilidade automÃ¡tica e scale-to-zero em aÃ§Ã£o

### Contato

ğŸ‘¨â€ğŸ’» **Diogo Carvalho de Matos**  
ğŸ¢ **Cargo:** Arquiteto de Software e SoluÃ§Ãµes  
ğŸ“§ **Email:** diogo.matos@castgroup.com.br

ğŸ’» **Demo:** Spring Boot + Knative + Kubernetes On-Premise

### Recursos da ApresentaÃ§Ã£o

- ğŸ“„ Este README completo
- ğŸ’» CÃ³digo da demonstraÃ§Ã£o: [GitHub Repository]
- ğŸ¥ GravaÃ§Ã£o: [Link se disponÃ­vel]

---

**ğŸš€ Obrigado pela atenÃ§Ã£o!**
